# ChatFlow Component Specification

> The core UI component for interactive Hoplets - conversational flow multi-turn solving interface

> **Relationship with ViewSpec**: This document describes the **design philosophy, data flow, state machine, and implementation details** (Transport layer, Service layer, Frontend layer) of the ChatFlow component. Specific UI interaction declarations (Zone breakdown, element tables, event step sequences, event routing) follow the Zone-per-file format in `Terms/ViewSpec格式规范.md`, declared in each task's `View/ViewSpec/tabs/<tab_id>/` directory. When this document conflicts with ViewSpec Zone files, ViewSpec takes precedence.

---

## 1. File Routing (Critical)

ChatFlow code is distributed across multiple files. Before modifying, confirm you're editing the correct file.

| File | Role | When Read |
|------|------|-----------|
| `hoplogic/hop_view/templates/base.html` | **Runtime HTML + JS**. Jinja2 template, rendered into complete HTML page once at startup by `build_index_html()`. All JS interaction logic is in this file. | Every app startup |
| `hoplogic/hop_view/css_templates/chatflow.css` | **Runtime CSS**. Injected as `<style>` tag by `html_builder._read_css()` when `interactive=True`. | Every app startup |
| `hoplogic/hop_view/templates/fragments/run_result.html` | **HTML fragment template**. Rendered by `renderer.render_run_result()` on each API call, pushed to frontend via SSE. | Every API request |
| `hoplogic/hop_view/html_builder.py` | Assembly entry: read CSS + render base.html → complete page string. | Every app startup |
| `hoplogic/hop_view/transport.py` | FastAPI endpoint definitions (including SSE endpoints). | Every API request |
| `Tasks/*/View/index.html` | **Snapshot file** generated by `/code2view`. **Not involved in runtime**, for reference only. | Never |

**Rule: Modify JS → edit `base.html`; modify CSS → edit `chatflow.css`; modify card structure → edit `fragments/run_result.html`. Never modify runtime behavior by changing `Tasks/*/View/index.html`.**

---

## 2. Positioning and Overview

ChatFlow is the **core interaction component in the Frontend layer** of the HopletView five-layer architecture, designed specifically for interactive mode (`Run Mode: Interactive`) Hoplets. It maps the engine layer's `LACK_OF_INFO → feedback → continue solving` loop into a user-visible conversational flow interface.

### Zone Breakdown

| Zone | DOM ID | Responsibility |
|------|--------|----------------|
| InputArea | `#solve-input-area` | Top input form (auto-generated from `config.input_fields`), collapses (`.collapsed`) after first submission |
| ChatFlow | `#chat-flow` | Middle message flow: user bubbles, system bubbles (thinking/result cards), initially `display:none` |
| ChatInputBar | `#chat-input-bar` | Bottom feedback bar: feedback input + Send + Confirm, visibility controlled by `.visible` CSS class |

### Architecture Position

```
┌─────────────────────────────────────────────────────────────┐
│  base.html (Jinja2 rendered, generated at startup)          │
│  ┌─────────────────────────────────────────────────────────┐│
│  │  Tab Bar: [solve] [batch] [history] [stats] [perf]      ││
│  ├─────────────────────────────────────────────────────────┤│
│  │  #solve-input-area           Initial input form          ││
│  │  #chat-flow                  Message flow               ││
│  │    .msg.msg-user             User bubbles (right-aligned) ││
│  │    .msg.msg-system           System bubbles (left-aligned) ││
│  │      .thinking               Waiting (step rotation + cancel) ││
│  │      .lack-info-card         Missing information         ││
│  │      .error-card             Error (with retry)          ││
│  │      .result-card            OK result                   ││
│  │      .confirmed-card         User confirmation           ││
│  │      .info-card              System prompt (cancel etc.) ││
│  │  #chat-input-bar             Bottom feedback bar         ││
│  └─────────────────────────────────────────────────────────┘│
│       │                                                    │
│       │  SSE: POST /api/run/init → GET /api/run/stream/{id}  │
│       │  SSE: POST /api/feedback/init → GET /api/feedback/... │
└───────┼──────────────────────────────────────────────────────┘
        │
   transport.py (FastAPI endpoints + SSE queues)
        │
   BaseService (hop_view.service)     ← session management
        │  ._sessions[session_id]
        │  ._session_inputs[session_id]
        │  ._session_iterations[session_id]
        │
   main_hop_func (Hoplet)             ← business logic
        │
   HopSession.hop_get()               ← operator calls
        │  returns (HopStatus, result)
```

### Relationship with Batch Mode

| Dimension | Interactive Mode (ChatFlow) | Batch Mode |
|-----------|----------------------------|------------|
| Transport | SSE two-phase flow (init + stream) | Synchronous `POST /api/run` |
| Non-OK Handling | Shows feedback area, waits for user input | Records result directly |
| Session | Maintained across multiple rounds | Released after single execution |
| Cancel Support | Yes (SSE connection can be closed) | Yes (batch can be aborted) |

---

## 3. Transport Layer: SSE Two-Phase Flow

### Why Use SSE

WKWebView (macOS pywebview kernel) has built-in timeouts for HTTP requests. LLM calls may take tens of seconds, blocking `fetch` will be killed with "Load failed".

SSE (Server-Sent Events) solution:
1. `POST /api/run/init` immediately returns `{stream_id}` (millisecond-level, no timeout)
2. `GET /api/run/stream/{id}` establishes `EventSource` long connection
3. Server sends `: ping N\n\n` keep-alive every 5 seconds (SSE comment frame, browser ignores but connection stays alive)
4. After LLM completes, pushes `data: {...}\n\n` result event
5. Frontend closes EventSource after receiving result

Uses native `EventSource` API (not `fetch + ReadableStream`), because WKWebView doesn't apply HTTP timeout to SSE connections.

### Protocol Sequence

```
Client                                  Server
  │                                       │
  │── POST /api/run/init ────────────────>│ body: {task_description, context}
  │<─ 200 {"stream_id":"uuid"} ──────────│ Returns immediately, starts asyncio.Task in background
  │                                       │
  │── GET /api/run/stream/{id} ─────────>│ EventSource connection
  │<─ ": ping 1\n\n" ───────────────────│ 5s no data
  │<─ ": ping 2\n\n" ───────────────────│ 10s no data
  │<─ "data: {json}\n\n" ───────────────│ LLM completed
  │   EventSource.close()                │ Client closes
  │                                       │ Cleanup _pending_streams[id]
```

### SSE Result Message Format

```json
{
  "type": "result",
  "html": "<div class='lack-info-card' data-hop-status='LACK_OF_INFO' data-session-id='uuid'>...</div>",
  "session_id": "uuid-or-empty",
  "hop_status": "OK|FAIL|LACK_OF_INFO|UNCERTAIN"
}
```

- `html`: Jinja2 rendered HTML fragment (`run_result.html`), directly inserted into DOM
- `session_id`: Session ID assigned by Service layer, frontend uses this to maintain `_sessionId`
- `hop_status`: Used for frontend state branching (show/hide chat input)

### Server Implementation (transport.py)

```python
_pending_streams: dict[str, asyncio.Queue[str | None]] = {}

@app.post("/api/run/init")
async def init_run_stream(req: RunTaskRequest) -> JSONResponse:
    stream_id = str(uuid4())
    queue = asyncio.Queue()
    _pending_streams[stream_id] = queue
    asyncio.create_task(_run(queue, req))       # Background execution
    return JSONResponse({"stream_id": stream_id})  # Return immediately

@app.get("/api/run/stream/{stream_id}")
async def stream_run_result(stream_id: str):
    queue = _pending_streams[stream_id]         # 404 if missing
    async def _events():
        while True:
            data = await wait_for(queue.get(), timeout=5.0)
            # TimeoutError → yield ": ping N\n\n"
            # None sentinel → break
            # else → yield f"data: {data}\n\n"
    return StreamingResponse(_events(), media_type="text/event-stream")
```

Feedback endpoints `/api/feedback/init` + `/api/feedback/stream/{id}` have identical structure.

### Backward Compatibility

Old endpoints `POST /api/run` and `POST /api/feedback` still exist, non-interactive views (HTMX form mode) continue to use them. ChatFlow uses dedicated SSE endpoints.

---

## 4. State Machine

### State Transition Diagram

```
                        ┌──────────┐
                        │ INITIAL  │  InputArea visible, ChatFlow hidden
                        └────┬─────┘
                             │ onSendTask()
                             ▼
                        ┌──────────┐
              ┌────────>│ THINKING │<──────────────────────┐
              │         └────┬─────┘ SSE stream pending    │
              │              │                             │
              │    ┌─────────┼──────────┐                  │
              │    │    hop_status?     │                  │
              │    ▼         ▼          ▼                  │
              │   OK    LACK_OF_INFO  FAIL/error           │
              │   │     UNCERTAIN       │                  │
              │   │         │           │                  │
              │   ▼         ▼           ▼                  │
              │ ┌────┐  ┌──────────┐  ┌───────┐           │
              │ │DONE│  │AWAITING  │  │ ERROR │           │
              │ └────┘  │FEEDBACK  │  └───┬───┘           │
              │ Final   └────┬─────┘      │ onRetryTask() │
              │              │             └───────────────┘
              │              │ onSubmitFeedback()
              │              │ onConfirm()
              │              └─────────────────────────────┘
              │
              │         ─── onCancelTask() ───
              │         (Can trigger in THINKING state)
              │              │
              │    ┌─────────┴──────────┐
              │    │ _sessionId set?    │
              │    ▼                    ▼
              │ ┌────────────┐  ┌─────────────────┐
              │ │ CANCELLED  │  │ CANCELLED       │
              │ │ (feedback) │  │ (initial run)   │
              │ │ chat input │  │ retry button    │
              │ │ visible    │  │ chat input      │
              │ └──────┬─────┘  │ hidden          │
              │        │        └────────┬────────┘
              │        │ onSubmitFeedback │ onRetryTask()
              └────────┴─────────────────┘
```

### HopStatus to UI Mapping

| hop_status | Message Card | chat input | `_sessionId` | Can Continue |
|------------|--------------|------------|--------------|--------------|
| `OK` | `.result-card` | hidden | cleared to null | No |
| `CONFIRMED` | `.confirmed-card` | hidden | cleared to null | No |
| `LACK_OF_INFO` | `.lack-info-card` | **visible** | set from SSE | Yes (feedback) |
| `UNCERTAIN` | `.lack-info-card` | **visible** | set from SSE | Yes (feedback/confirm) |
| `FAIL` | `.error-card` (with retry) | hidden | **retained** | Yes (retry) |
| (transport error) | inline `.error-card` (with retry) | visible | unchanged | Yes (retry) |
| `CANCELLED` | `.info-card` | hidden | cleared to null | No |

**Key Distinction**:
- **FAIL vs Transport Error**: FAIL comes from engine layer (verification failure/capability limitation), transport error comes from SSE connection interruption. Both show error card + retry button, but FAIL retains `_sessionId`, transport error keeps `_sessionId` unchanged.
- **LACK_OF_INFO vs UNCERTAIN**: LACK_OF_INFO missing critical information, UNCERTAIN solution generated but uncertain. Both allow feedback, UNCERTAIN additionally shows Confirm button.

### Two Cancel Scenarios

This is the most error-prone state transition, must be strictly distinguished:

| Scenario | Condition | UI Behavior | User Follow-up |
|----------|-----------|-------------|----------------|
| Cancel initial run | `_sessionId === null` | info card + "Retry" button | Click retry → `onRetryTask()` |
| Cancel feedback loop | `_sessionId !== null` | info card + chat input visible | Re-enter → `onSubmitFeedback()` |

**Why different**: When canceling initial run, `_sessionId` hasn't been set yet (UNCERTAIN result hasn't arrived), `onSubmitFeedback` has `if (!text || !_sessionId) return` guard, showing chat input would cause user input to Send with no response (silent no-op).

---

## 5. Frontend State Variables

```javascript
// --- Session State ---
let _sessionId = null;            // Current session ID (from SSE result.session_id)
let _feedbackRound = 0;           // Feedback round (only for > MAX_FEEDBACK check)
let _conversationActive = false;  // Whether conversation is active
let _lastResult = null;           // Most recent result (for confirm)

// --- SSE Stream Control ---
let _cancelled = false;           // Whether user has cancelled current operation
let _currentStream = null;        // Current EventSource instance (closed on cancel)
let _lastAction = null;           // {initUrl, body, summary?} — for onRetryTask() replay

// --- Thinking Animation ---
let _thinkingTimer = null;        // setInterval ID (step rotation 8s/step)
let _thinkingStep = 0;            // Current step index

// --- Retry Quota ---
let _retryCount = 0;              // Number of retries attempted

// --- Constants (Jinja2 injected) ---
const _HOP_THINKING_STEPS = [...];  // Step label list
const _HOP_RETRY_QUOTA = Infinity;  // Maximum retry count
const MAX_FEEDBACK = 5;              // Maximum feedback rounds
```

### `_lastAction` Design

`_lastAction` is set before each SSE call, recording request parameters:

```javascript
// In onSendTask:
_lastAction = {initUrl: "/api/run/init", body: {task_description, context}, summary: "..."};

// In onSubmitFeedback:
_lastAction = {initUrl: "/api/feedback/init", body: {session_id, feedback}};
```

`onRetryTask()` directly reuses `_lastAction.initUrl` and `_lastAction.body` to retry the SSE flow, without distinguishing between run or feedback retries.

### Server-Authoritative State Rules

- Display values come from server response, not frontend counters (`_feedbackRound` only controls flow)
- `_sessionId` only source is SSE `msg.session_id`
- `hop_status` only source is SSE `msg.hop_status`

---

## 6. Core Events

### onSendTask() (First Submission)

```
1. Validation: at least one input_field non-empty
2. Build body: {field_name: value, ...}
3. Collapse input area: #solve-input-area.classList.add("collapsed")
4. Show message flow: #chat-flow.style.display = "flex"
5. Append user bubble: desc[0].slice(0,100) + " | " + desc[1].slice(0,50)
6. Append thinking bubble (with step rotation + cancel button)
7. Set _lastAction = {initUrl: "/api/run/init", body, summary}
8. SSE Phase 1: POST /api/run/init → {stream_id}
   - Failure: removeThinking → error card (with retry) → showChatInput
9. SSE Phase 2: EventSource("/api/run/stream/" + streamId)
   - onmessage(result): see "SSE Result Handling"
   - onerror: removeThinking → error card (with retry) → showChatInput
```

### onSubmitFeedback() (Feedback Submission)

```
1. Guard: if (!text || !_sessionId) return     ← Critical: _sessionId must be set
2. Clear input box, _feedbackRound++
3. Append user bubble(text)
4. Append thinking bubble
5. Set _lastAction = {initUrl: "/api/feedback/init", body: {session_id, feedback}}
6. SSE Phase 1: POST /api/feedback/init → {stream_id}
7. SSE Phase 2: EventSource("/api/feedback/stream/" + streamId)
   - Same handling as onSendTask
```

### onCancelTask() (Cancel)

```
1. _cancelled = true
2. if (_currentStream) { _currentStream.close(); _currentStream = null; }
3. removeLastThinking()
4. if (_sessionId) {
     // --- Feedback loop cancel: session valid, user can re-enter ---
     appendSystemHtml: info-card "Cancelled. You can revise and resubmit."
     showChatInput()
     POST /api/cancel {session_id}   // Notify server to cancel background task
     // Retain _sessionId (session state still valid)
   } else {
     // --- Initial run cancel: session not established, only retry ---
     appendSystemHtml: info-card "Cancelled." + retry button
     // Don't show chat input (_sessionId is null, onSubmitFeedback will silent return)
   }
5. scrollToBottom()
```

### onRetryTask() (Retry)

```
1. Guard: if (!_lastAction) return
2. _cancelled = false
3. Append thinking bubble
4. SSE Phase 1: POST _lastAction.initUrl → {stream_id}
5. SSE Phase 2: EventSource(_lastAction.initUrl.replace("/init", "/stream/") + streamId)
   - Same handling as onSendTask
```

Retry doesn't distinguish between run or feedback, directly replays `_lastAction`.

### onConfirm() (Confirm Solution)

```
1. Guard: if (!_sessionId) return
2. Call onSubmitFeedbackWithText("confirm")
   → Equivalent to user input "confirm" and Submit
```

### SSE Result Handling (Shared by Three Events)

```javascript
es.onmessage = e => {
  const msg = JSON.parse(e.data);
  if (msg.type === "result") {
    streamDone = true;
    es.close(); _currentStream = null;
    if (_cancelled) return;              // Already cancelled, discard delayed result
    removeLastThinking();
    if (msg.session_id) _sessionId = msg.session_id;
    appendSystemHtml(msg.html);          // Insert HTML + scan data-* attributes
    if (hopStatus is UNCERTAIN/LACK_OF_INFO) → showChatInput();
    else → hideChatInput(); if (not FAIL) _sessionId = null;
  }
};
```

### appendSystemHtml() data-attribute Scanning

HTML fragments are rendered by Jinja2 on the server, carrying state information via `data-*` attributes:

```html
<div class="lack-info-card"
     data-hop-status="LACK_OF_INFO"
     data-session-id="uuid">
  ...
</div>
```

After `appendSystemHtml()` inserts HTML, it scans `[data-hop-status]`:
- Extracts `data-session-id` → sets `_sessionId`
- `UNCERTAIN | LACK_OF_INFO` → `showChatInput()`
- `OK | CONFIRMED | CANCELLED` → `hideChatInput()` + `_sessionId = null`

**Why use data-attribute**: `<script>` tags inserted via `insertAdjacentHTML` won't execute (HTML spec). data-attribute is the only reliable server→frontend state channel.

---

## 7. Message Card Rendering

All cards are rendered server-side by Jinja2 template `fragments/run_result.html`, inserted by frontend via `appendSystemHtml()`.

### run_result.html Branch Logic

```
if error and no hop_status:
  → .error-card + ERROR badge + retry button

elif CANCELLED:
  → .info-card "Task cancelled."

elif LACK_OF_INFO / UNCERTAIN:
  → .lack-info-card + badge + clarification list + summary + chart + Raw JSON

elif FAIL:
  → .error-card + FAIL badge + retry button

else (OK / CONFIRMED):
  → .result-card (.confirmed-card if CONFIRMED) + badge + gauge + summary + errors + chart + Raw JSON
```

### Thinking Bubble

```
.thinking-msg
  .system-bubble
    .thinking
      .thinking-summary        ← Task summary (optional)
      .thinking-steps          ← Sliding window (max 3 steps)
        .thinking-step.completed  ← Previous step: ✓
        .thinking-step.active     ← Current step: spinner
        .thinking-step.pending    ← Next step: ○
      button.btn-stop          ← Cancel button ■
```

**Step Rotation**: 8 seconds/step, sliding window shows max 3 steps. Stops after reaching final step. `removeLastThinking()` clears timer + removes DOM.

### CSS Key Constraints

- `.msg-bubble` defaults to `white-space: pre-wrap` (user bubbles preserve line breaks)
- `.system-bubble` overrides to `white-space: normal` (prevents Jinja2 template indentation from rendering as visible whitespace)
- `.chat-input-bar` defaults to `display: none`, `.visible` class toggles to `display: flex`

---

## 8. Service Layer

Session management is provided by `hop_view.service.BaseService`.

### Usage

```python
service = BaseService(VIEW_CONFIG, HOPLET_DIR, TESTCASES_DIR,
    observer=HopletObserver(OBSERVER_LOG))

result = await service.run_task(input_data)
# → {"session_id": "uuid", "hop_status": "OK|FAIL|LACK_OF_INFO|UNCERTAIN", "iteration": 1, ...}

result = await service.submit_feedback(session_id, feedback)
result = await service.retry_task(session_id)
result = await service.cancel_task(session_id)
```

### Session Lifecycle

```
run_task()
  ├── OK         → session.__aexit__() → fully released
  ├── FAIL       → session.__aexit__() → release session, retain input/iterations
  └── LACK_OF_INFO/UNCERTAIN → session kept alive
        │
        └── submit_feedback()
              ├── OK/CONFIRMED → session.__aexit__() → fully released
              ├── FAIL         → session.__aexit__() → release session, retain input/iterations
              └── LACK_OF_INFO/UNCERTAIN → keep alive, continue loop

retry_task(session_id)
  └── read retained input_data → create new session → execute

cancel_task(session_id)
  └── task.cancel() → session.__aexit__() → release
```

### FAIL Session Retention Policy

| Field | FAIL Behavior | Description |
|-------|---------------|-------------|
| `_sessions` | Cleared | context released |
| `_session_inputs` | **Retained** | needed for retry |
| `_session_iterations` | **Retained** | iteration continues incrementing on retry |
| `_session_errors` | Recorded | tracks retry count |
| `_running_tasks` | Cleared | task completed |

### Engine Layer API

```python
class HopSession:
    def add_feedback(self, feedback: str) -> None:
        """Append feedback to run_history as user message"""
        self.append_run_message("user", feedback)
```

After feedback injection, LLM sees: `[user: task, assistant: previous result, user: feedback, ...]`.

---

## 9. API Endpoints

### SSE Endpoints (ChatFlow Specific)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/run/init` | POST | Start task, immediately returns `{stream_id}` |
| `/api/run/stream/{id}` | GET | SSE stream: ping keep-alive + result events |
| `/api/feedback/init` | POST | Start feedback, immediately returns `{stream_id}` |
| `/api/feedback/stream/{id}` | GET | SSE stream: same as above |

### Synchronous Endpoints (Non-interactive Views/Backward Compatibility)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/run` | POST | Blocking execution, returns HTML fragment |
| `/api/feedback` | POST | Blocking feedback, returns HTML fragment |
| `/api/retry` | POST | Retry, returns HTML fragment |
| `/api/cancel` | POST | Cancel, returns JSON |

---

## 10. Design Constraints

### 10.1 FAIL vs LACK_OF_INFO Boundary

`add_feedback` only affects LLM conversation history, cannot fix pipeline layer issues.

| Failure Source | Correct Status | Can Continue with Feedback |
|----------------|----------------|---------------------------|
| Pre-pipeline failure (RAG/data source) | FAIL | No |
| Transport failure/verification failure | FAIL | No |
| LLM reports missing information | LACK_OF_INFO | Yes |
| LLM reports uncertainty | UNCERTAIN | Yes |

**Hop.py Author Rule**: Pipeline failure → return FAIL (call `hop_exit`), don't return LACK_OF_INFO.

### 10.2 pywebview Environment Constraints

- **Unified HTTP**: pywebview accesses same FastAPI app via embedded uvicorn
- **Text Selectable**: Global `* { user-select: text }`
- **Error Overlay**: `#error-overlay` captures `window.error` + `unhandledrejection`
- **SSE No Timeout**: WKWebView doesn't apply HTTP timeout to `EventSource` connections (solves "Load failed")

### 10.3 Whitespace Trap

`.msg-bubble` defaults to `white-space: pre-wrap` to preserve user input line breaks. But Jinja2 template indentation also renders as visible blank lines. Solution: `.system-bubble { white-space: normal; }` override.

Be careful with this when adding new system bubble styles.

### 10.4 `insertAdjacentHTML` Script Limitation

HTML spec states `<script>` tags inserted via `insertAdjacentHTML` won't execute. Server-rendered HTML fragments cannot rely on inline scripts, must use `data-*` attributes to pass state, processed by `appendSystemHtml()`.

### 10.5 Common Pitfalls (Real Experience)

Following are typical issues encountered during ChatFlow's initial integration, listed as permanent design constraints.

#### Pitfall 1: Task-level ViewSpec vs Shared Component ViewSpec Desync

**Symptom**: AI generates code calling non-existent sync endpoints (like `POST /api/run`) based on task ViewSpec, runtime 404.
**Root Cause**: Shared ChatFlow ViewSpec (`hoplogic/hop_view/chatflow/ViewSpec/`) switched to Two-Phase SSE protocol, but task-level ViewSpec (`Tasks/*/View/ViewSpec/tabs/solve/`) still describes old sync HTTP endpoints. AI generates code based on task ViewSpec, inconsistent with runtime.
**Rule**: Task-level ViewSpec's ChatFlow/ChatInputBar Zone files **must reference shared ViewSpec**, only describe customization points (thinking_steps, handleResponse branch details, placeholder mappings etc.), must not repeat protocol details. Format:

```markdown
> Shared implementation: [`hoplogic/hop_view/chatflow/ViewSpec/zones/ChatFlow.md`](...)
> This file only describes customization points. General behavior see shared ViewSpec.
```

#### Pitfall 2: Template Field Lookup Chain Incomplete

**Symptom**: LACK_OF_INFO card's clarification list empty despite Hop.py returning `clarification_needed` field.
**Root Cause**: `run_result.html`'s field lookup chain `clarification_questions || missing_info` missed `clarification_needed`. Different Hoplets use different field names for same semantics.
**Rule**: Each lookup chain in `run_result.html` must cover all known field aliases. When adding new Hoplet, if output field name not in existing lookup chain, must sync update template. Current complete lookup chains:

| Semantics | Lookup Chain |
|-----------|--------------|
| Clarification List | `clarification_questions` → `clarification_needed` → `missing_info` |
| Summary Text | `answer` → `summary` → `verification_summary` → `presentation` → `problem_summary` |

#### Pitfall 3: Hop.py HopStatus Branch Missing

**Symptom**: When `generate_solution` step returns LACK_OF_INFO, UI shows `"Solution generation failed: {}"`.
**Root Cause**: Only `analyze_problem` step in Hop.py has dedicated LACK_OF_INFO handling, `generate_solution` step's LACK_OF_INFO falls into generic `status != OK` branch, formatted as error string.
**Rule**: In interactive mode Hop.py, **every operator call that may return LACK_OF_INFO/UNCERTAIN must have dedicated handling branch**, cannot rely on generic error fallback. Checklist:
- [ ] Every `hop_get`/`hop_judge` call checked for `if status == HopStatus.LACK_OF_INFO:` branch
- [ ] LACK_OF_INFO branch output dict must contain `clarification_needed` list (non-empty)
- [ ] UNCERTAIN branch output dict must contain `presentation` or `summary`

#### Pitfall 4: Wrong File Modified (Snapshot vs Runtime Template)

**Symptom**: No UI change after modifying `Tasks/*/View/index.html`.
**Root Cause**: `index.html` is static snapshot generated by `/code2view`, runtime uses dynamic rendering from `base.html` + `chatflow.css` + `run_result.html`.
**Rule**: See §1 file routing table. Task ViewSpec's `index.md` should include file routing table (see `Terms/ViewSpec格式规范.md` §1.7).

#### Pitfall 5: Coroutine Events Missing Guard Declaration

**Symptom**: Start button can be clicked continuously, causing multiple SSE streams to write to same `#chat-flow` container, messages interleaved.
**Root Cause**: ViewSpec ChatFlow.md's `task_submit` event didn't declare `guard: _conversationActive, .btn-send`, code generation/manual implementation missed reentrancy guard.
**Rule**: Each `[coroutine]` event in ViewSpec **must explicitly declare three types of guards** (state variable guard, element guard, event mutual exclusion guard), and must declare resume function (like `_unlockSend()`). All final state paths (OK/FAIL/CONFIRMED/error/cancel) must call resume function. Checklist:
- [ ] Each `[coroutine]` event has `> guard:` line
- [ ] guard includes state variable (anti-reentrancy), trigger button (UI feedback), mutual exclusion events
- [ ] Resume function name declared, called by all final state paths
- [ ] `test_html_builder.py` has corresponding constraint tests

#### Pitfall 6: Service Layer Keyword Matching Missing i18n Coverage

**Symptom**: After user inputs "确认", system treats it as regular feedback to LLM, returns irrelevant answer.
**Root Cause**: `BaseService._is_confirmation()` only recognizes English "confirm"/"ok", misses Chinese "确认"/"好的"/"可以" etc.
**Rule**: Any string matching/keyword recognition logic in Service layer must declare keywords as explicit constant tuples in code (like `_CONFIRM_PREFIXES`), must cover Chinese/English. Checklist:
- [ ] Keywords declared as module-level or class-level constants (not inline literals)
- [ ] Constants comments list all supported languages
- [ ] Parameterized tests cover all keywords (`@pytest.mark.parametrize`)
- [ ] Adding language only needs extending constant tuple + adding parametrize cases

---

## 11. Test Coverage

### Transport Tests (test_transport.py)

| Test | Coverage |
|------|----------|
| `test_init_run_stream_returns_stream_id` | POST /api/run/init returns stream_id |
| `test_stream_delivers_result_event` | GET /api/run/stream/{id} pushes result |
| `test_stream_unknown_id_returns_404` | Unknown stream_id returns 404 |
| `test_init_feedback_stream_returns_stream_id` | POST /api/feedback/init |
| `test_feedback_stream_delivers_result` | GET /api/feedback/stream/{id} |

### Frontend Static Checks (test_web.py)

| Test | Coverage |
|------|----------|
| `test_global_user_select_text` | `*` selector enables text selection |
| `test_error_overlay_exists` | error-overlay element exists |

### Service Tests (test_service.py)

| Test | Coverage |
|------|----------|
| `test_post_run` | Normal execution |
| `test_post_feedback` | Feedback submission |
| `test_feedback_loop` | Multi-round iteration incrementing |

---

## 12. Extension Points

- **LLM Streaming**: Stream LLM generated text fragments before SSE result arrives (needs engine layer callback)
- **Session Timeout Reclaim**: Automatically release sessions without feedback for long time
- **Multi-task Concurrency**: Left conversation list + right conversation flow
- **History Replay**: Persist conversation messages as JSONL

---

## 14. Observability

### 14.1 Frontend Debug Log

ChatFlow runtime state is invisible to Claude Code by default (JS memory state variables, UI error overlay disappears after 8 seconds). Frontend Debug Log mechanism solves this.

#### Two-layer Design

| Layer | Trigger Condition | Write File | Purpose |
|-------|-------------------|------------|---------|
| Error Persistence | Always active | `TestCases/frontend-debug.jsonl` | Frontend errors (JS exceptions, network failures) POST to backend write JSONL |
| State Change Debug Log | `HOP_VIEW_DEBUG=1` or `--debug` | `TestCases/frontend-debug.jsonl` | Key state variable changes logged to JSONL + UI debug panel |

#### Enable Method

```bash
HOP_VIEW_DEBUG=1 uv run view <TaskName>
```

#### Log Format (JSONL)

```json
{"ts": "2026-01-15T10:30:00.123Z", "level": "state", "message": "_sessionId = 'uuid-xxx' (from SSE)", "context": null}
{"ts": "2026-01-15T10:30:01.456Z", "level": "error", "message": "HTTP 500", "context": null}
```

| Field | Type | Description |
|-------|------|-------------|
| `ts` | string | ISO 8601 timestamp |
| `level` | string | `"error"` / `"state"` / `"event"` / `"warn"` |
| `message` | string | Human-readable description |
| `context` | object \| null | Optional context data |

#### State Variable Instrumentation

All changes to these 5 state variables have `_hopLog("state", ...)` calls:

- `_sessionId` — 4 places (appendSystemHtml set/clear, _handleResult set/clear)
- `_conversationActive` — 2 places (onSendTask set true, _unlockSend set false)
- `_cancelled` — 4 places (onSendTask/onSubmitFeedback/onRetryTask reset, onCancelTask set true)
- `_feedbackRound` — 1 place (onSubmitFeedback increment)
- `_currentStream` — 4 places (_openStream set, _handleResult/handleStreamError/onCancelTask clear)

#### Rules

When adding new coroutine events, **must sync add state change `_hopLog` calls**. Checklist:
- [ ] Event entry has `_hopLog("event", "event: <name>")` call
- [ ] Guard interception has `_hopLog("event", "event: <name> BLOCKED (...)")` call
- [ ] Each state variable change has `_hopLog("state", "<var> = <value> (<caller>)")` call

#### Log File Lifecycle

`frontend-debug.jsonl` is not automatically cleared on View restart, convenient for Claude Code post-analysis. Manual cleanup:
```bash
rm Tasks/<TaskName>/TestCases/frontend-debug.jsonl
```

---

## 15. Relationship with Other Specifications

| Specification | Relationship |
|---------------|--------------|
| `Terms/HopletView架构规范.md` | ChatFlow is the interaction component in Frontend layer of five-layer architecture |
| `Terms/ViewSpec格式规范.md` | ChatFlow layout type `chat-flow` declared in ViewSpec tabs/*.md |
| `Terms/HopView共享库规范.md` | BaseService session management detailed API |
| `hoplogic/docs/hop_feedback_solving.md` | Engine layer feedback continuation mechanism |
| `Terms/HOP核心算子.md` | HopStatus enum drives state transitions |
| `.claude/commands/code2view.md` | `/code2view` detects run mode, interactive mode generates ChatFlow |