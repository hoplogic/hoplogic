# 批量测试数据格式规范

本文档规范化 HOP 批量测试的输入/输出 JSONL 数据格式。

## 输入格式

每个测试用例为一行 JSON：

```jsonl
{"id": 1, "tag": "fabrication", "description": "...", "<input_fields>": "...", "expected_<output_field>": ...}
```

### 字段定义

| 字段 | 类型 | 必填 | 说明 |
|------|------|------|------|
| `id` | int | 是 | 唯一递增标识 |
| `tag` | string | 是 | 分类标签（用于分组统计） |
| `<input_fields>` | per contract | 是 | metainfo 输入契约的所有字段 |
| `description` | string | 否 | 测试用例描述 |
| `expected_<field>` | per contract | 否 | 预期输出值（用于自动化比对） |
| `difficulty` | string | 否 | "easy" / "medium" / "hard" |

### Verify 任务输入示例

```jsonl
{"id": 1, "tag": "fabrication", "description": "完全虚构的数据", "context_window": "A公司2023年营收120亿元", "model_output": "A公司2023年营收200亿元", "expected_hallucination_detected": true}
{"id": 2, "tag": "clean", "description": "忠实原文的输出", "context_window": "B公司成立于2010年", "model_output": "B公司成立于2010年", "expected_hallucination_detected": false}
```

## 输出格式

批量测试结果同为 JSONL，但 **两个生产者使用不同的 wrapper 格式**：

| 生产者 | 命令 | wrapper 格式 | 示例 |
|--------|------|-------------|------|
| `batchhoptest` CLI | `/batchhoptest` | flat record + `hop_result` | `{"id":1, "question":"...", "hop_result":"{...}"}` |
| View `_batch_worker` | UI 批量测试 | `{"input":{...}, "result":"..."}` | `{"input":{"question":"..."}, "result":"{...}"}` |

两种格式在同一个 `TestCases/` 目录共存。**消费方必须处理两种格式**：

- `BaseDataStore._normalize_audit()` — 两种格式均可解析（嵌套 `result` 字段会自动解包）
- `BaseService._batch_worker` — 输入文件可能是原始输入或之前的批量输出，通过 `_normalize_input()` 自动解包（见下文「输入归一化」节）

### 元数据行

`_type: meta` 行记录 profile 配置信息，每个 profile 一行：

```jsonl
{"_type": "meta", "profile": "kimi-full", "run_llm": "Kimi-K2-Instruct-0905", "verify_llm": "Kimi-K2-Instruct-0905", "run_params": {"temperature": 0.1, "max_tokens": 4000}, "timestamp": "2026-02-19T10:30:00"}
```

| 字段 | 类型 | 说明 |
|------|------|------|
| `_type` | string | 固定 "meta" |
| `profile` | string | Profile 名称 |
| `run_llm` | string | 执行 LLM 模型名 |
| `verify_llm` | string | 核验 LLM 模型名 |
| `run_params` | object | 执行参数（temperature, max_tokens 等） |
| `timestamp` | string | ISO 8601 时间戳 |

### 结果行

每条测试结果包含原始输入 + HOP 执行结果：

```jsonl
{"id": 1, "tag": "fabrication", "context_window": "...", "model_output": "...", "hop_result": "{...}", "hop_stats": {"retry_count": 0, "execution_path": [...], "status": "OK"}, "profile": "kimi-full"}
```

| 字段 | 类型 | 说明 |
|------|------|------|
| `hop_result` | string (JSON) | Hop 函数返回值（JSON 字符串） |
| `hop_stats` | object | 执行统计 |
| `hop_stats.retry_count` | int | 重试次数 |
| `hop_stats.execution_path` | array | 执行路径 |
| `hop_stats.status` | string | "OK" / "ERROR" |
| `hop_stats.error` | string | 错误信息（仅 status=ERROR 时） |
| `profile` | string | Profile 名称 |

### View 批量输出格式

View UI 的 `_batch_worker` 输出每条记录包装为：

```jsonl
{"input": {"question": "HOP 是什么？"}, "result": "{\"answer\": \"...\", \"confidence\": \"High\", ...}"}
{"input": {"question": "fail case"}, "error": "timeout"}
```

| 字段 | 类型 | 说明 |
|------|------|------|
| `input` | object | 原始输入（解包后的输入契约字段） |
| `result` | string (JSON) | Hop 函数返回值（JSON 字符串），成功时存在 |
| `error` | string | 错误信息，失败时存在 |

## 输入归一化

`BaseService._normalize_input()` 在批量执行前自动解包输入记录，使用户可以选择任何 JSONL 文件作为批量输入（原始输入文件或之前的批量输出文件）：

```
输入记录 → _normalize_input() → 原始输入 → hop_func()
```

识别规则：

| 条件 | 判定 | 操作 |
|------|------|------|
| `rec["input"]` 是 dict 且 `"result"` 或 `"error"` 存在 | View 批量输出 | 返回 `rec["input"]` |
| 其他 | 原始输入或 batchhoptest 格式 | 返回 `rec` 原样 |

**幂等性保证**：输出也存储解包后的 `input_data`（非原始 `rec`），避免重复执行时层层嵌套。

## DataStore 兼容性

- `_type: meta` 行由 `BaseDataStore._normalize_audit()` 自动跳过
- `profile` 字段自动传播到解析后的审计记录，支持 `get_stats(profile=...)` 筛选
- 嵌套在 `result` 字段中的 JSON 字符串会被自动解包

## Observer 日志 schema

`HopletObserver` 写入 `TestCases/observer.jsonl`，包含三种记录类型：

| type | 必有字段 | 可选字段 | 说明 |
|------|---------|---------|------|
| `run_start` | `run_id, timestamp, hoplet, input` | -- | 执行开始 |
| `run_end` | `run_id, timestamp, duration, status` | `result, metadata` | 执行结束 |
| `step` | `run_id, timestamp, step, op, task, status, duration` | `retry_count, metadata` | 算子步骤 |

**`step` 记录是可选的**：只有调用了 `tracer.trace_step()` 才会产生。如果 Hoplet 不做算子级追踪（如 RAGDemo 直接调用 `rag.retrieve()` + `session.hop_get()`，没有手动 trace_step），observer 日志中只有 `run_start/run_end` 记录。

`BaseDataStore.get_perf_summary()` 在查询 operator_stats 前**必须检查 `op` 列是否存在**（DuckDB 从 JSONL 推断 schema，无 step 记录则无 op 列）。
