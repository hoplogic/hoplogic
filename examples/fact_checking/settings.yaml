system_model_config:
  inference_engine: "bailian"
  openai:
    api_key: "/etc/bailian-key"  
    base_url: "your_base_url"
  model: "qwen-max"
  max_tokens: 5000  # 需要调大时修改此处
  temperature: 0.0
  # frequency_penalty: 0.0
  # max_completion_tokens: 1000
  # n: 1
  # stream: false
  # top_p: 1.0
  # timeout: 120
  # max_retry_count: 3 #模型最大重试次数

verify_model_config:
  inference_engine: "bailian"
  openai:
    api_key: "/etc/bailian-key"
    base_url: "your_base_url"
  model: "qwen-max"
  max_tokens: 4000  # 需要调大时修改此处
  temperature: 0.0
  # frequency_penalty: 0.0
  # max_completion_tokens: 1000
  # n: 1
  # stream: false
  # top_p: 1.0
  # timeout: 120
  # max_retry_count: 3 #模型最大重试次数
